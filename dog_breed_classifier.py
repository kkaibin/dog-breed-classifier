# -*- coding: utf-8 -*-
"""Dog breed classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1As3fPRiKAIMnwFYy930cW-aIddH66Gpr

#Import Libraries#
"""

# Import libraries
from sklearn.datasets import load_files       
from keras.utils import np_utils
import numpy as np
from glob import glob

import cv2     
import random

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from keras.preprocessing import image                  
from tqdm import tqdm

from PIL import ImageFile 

from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.layers import Dropout, Flatten, Dense
from keras.models import Sequential
from keras.layers import BatchNormalization

from keras.callbacks import ModelCheckpoint  

import random
random.seed(8675309)

"""#Import Datasets#"""

# mount google drive
from google.colab import drive
drive.mount('/content/gdrive')
# unzip datasets
!unzip '/content/gdrive/MyDrive/dog breed classifier/dogImages.zip'
!unzip '/content/gdrive/MyDrive/dog breed classifier/lfw.zip'

# define function to load train, test, and validation datasets
def load_dataset(path):
    data = load_files(path)
    files = np.array(data['filenames'])
    targets = np_utils.to_categorical(np.array(data['target']), 133)
    #targets = np.array(data['target'])
    return files, targets

# import dog datasets
train_files, train_targets = load_dataset('/content/dogImages/train')
valid_files, valid_targets = load_dataset('/content/dogImages/valid')
test_files, test_targets = load_dataset('/content/dogImages/test')
dog_names = [item[29:-1].replace("_"," ") for item in sorted(glob("/content/dogImages/train/*/"))]

# import human datasets
human_files = np.array(glob("/content/lfw/*/*"))

"""#Human and Dog Detectors#
Human detector: OpenCV\
Dog detector: pre-trained ResNet50 model(weights=ImageNet)
"""

# Human detector
face_cascade = cv2.CascadeClassifier('/content/gdrive/MyDrive/dog breed classifier/haarcascade_frontalface_alt.xml')

def face_detector(img_path):
    img = cv2.imread(img_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray)
    return len(faces) > 0

# Dog detector

ResNet50_model = ResNet50(weights='imagenet')

def path_to_tensor(img_path):
    # loads RGB image as PIL.Image.Image type
    img = image.load_img(img_path, target_size=(224, 224))
    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)
    x_3d = image.img_to_array(img)
    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor
    return np.expand_dims(x_3d, axis=0)

def ResNet50_predict_labels(img_path):
    # returns prediction vector for image located at img_path
    img = preprocess_input(path_to_tensor(img_path))
    return np.argmax(ResNet50_model.predict(img))

def dog_detector(img_path):
    prediction = ResNet50_predict_labels(img_path)
    return ((prediction <= 268) & (prediction >= 151))

#Accuracy test

#dataset for testing
human_files_short = human_files[:100]
dog_files_short = train_files[:100]

def detection(img_paths):
  human=0
  dog=0
  both=0
  total=len(img_paths)
  for img in img_paths:
    if face_detector(img) and not dog_detector(img): 
      human+=1
    elif dog_detector(img) and not face_detector(img):
        dog+=1
    else:
      if face_detector(img) and dog_detector(img):
        both+=1
  print("Humans:",human/total)
  print("Dogs:",dog/total)
  print("Both are detected:",both/total)
  print("Unknown species",(total-human-dog-both)/total)

print("Among 100 human photos:")
detection(human_files_short)
print("Among 100 dog photos:")
detection(dog_files_short)

"""# Data Preprocessing#"""

ImageFile.LOAD_TRUNCATED_IMAGES = True

def paths_to_tensor(img_paths):
    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]
    return np.vstack(list_of_tensors)

# pre-process the data for Keras
train_tensors = paths_to_tensor(train_files).astype('float32')/255
valid_tensors = paths_to_tensor(valid_files).astype('float32')/255
test_tensors = paths_to_tensor(test_files).astype('float32')/255

# data augmentation
from keras.preprocessing.image import ImageDataGenerator

# create and configure augmented image generator
datagen_train = ImageDataGenerator(
    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)
    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)
    horizontal_flip=True) # randomly flip images horizontally

# create and configure augmented image generator
datagen_valid = ImageDataGenerator(
    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)
    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)
    horizontal_flip=True) # randomly flip images horizontally

# fit augmented image generator on data
datagen_train.fit(train_tensors)
datagen_valid.fit(valid_tensors)

# visualize augmented data
import matplotlib.pyplot as plt

# take subset of training data
x_train_subset = train_tensors[:10]

# visualize subset of training data
fig = plt.figure(figsize=(20,2))
for i in range(10):
    ax = fig.add_subplot(1, 10, i+1)
    ax.imshow(x_train_subset[i])
fig.suptitle('Original Images', fontsize=15)
plt.show()

# visualize augmented data
fig = plt.figure(figsize=(20,2))
for x_batch in datagen_train.flow(x_train_subset, batch_size=10):
    for i in range(10):
        ax = fig.add_subplot(1, 10, i+1)
        ax.imshow(x_batch[i])
    fig.suptitle('Augmented Images', fontsize=15)
    plt.show()
    break;

"""#Model Architecture#"""

from keras.layers.advanced_activations import ReLU
# Model from scratch

model = Sequential()
# model.add(BatchNormalization(input_shape=(224, 224, 3)))
model.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu',input_shape=(224, 224, 3)))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())

model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())

model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())

model.add(Dropout(0.3))
model.add(Flatten())

#model.add(GlobalAveragePooling2D())

model.add(Dense(133, activation='softmax'))

model.summary()

# Compile the model
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

"""Keras fit_generatorçš„steps_per_epoch
https://zhuanlan.zhihu.com/p/165188660
"""

# Train the model

epochs = 20
batch_size = 20

checkpointer = ModelCheckpoint(filepath='/content/saved_models/weights.best.from_scratch.hdf5', 
                               verbose=1, save_best_only=True)

model.fit(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size), 
          validation_data=(valid_tensors, valid_targets),
          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)

# Test the model
model.load_weights('/content/saved_models/weights.best.from_scratch.hdf5')

# get index of predicted dog breed for each image in test set
dog_breed_pred = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]

# report test accuracy
test_accuracy = 100*np.sum(np.array(dog_breed_pred)==np.argmax(test_targets, axis=1))/len(dog_breed_pred)
print('Test accuracy: ',test_accuracy,'%')

"""#Transfer Learning#"""

# Transfer learning with VGG-16 bottleneck features

# Obtain bottleneck features
bottleneck_features = np.load('/content/gdrive/MyDrive/dog breed classifier/DogVGG16Data.npz')
train_VGG16 = bottleneck_features['train']
valid_VGG16 = bottleneck_features['valid']
test_VGG16 = bottleneck_features['test']

VGG16_model = Sequential()
VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))
VGG16_model.add(Dense(133, activation='softmax'))

VGG16_model.summary()

# Compiling
VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

# Train the model

epochs = 20
batch_size = 20

checkpointer = ModelCheckpoint(filepath='/content/saved_models/weights.best.VGG16.hdf5', 
                               verbose=1, save_best_only=True)
# Without data augmentation
VGG16_model.fit(train_VGG16, train_targets, 
          validation_data=(valid_VGG16, valid_targets),
          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)

# With data augmentation
# VGG16_model.fit(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size), 
#           validation_data=(valid_VGG16, valid_targets),
#           epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)

# Model Testing
VGG16_model.load_weights('/content/saved_models/weights.best.VGG16.hdf5')

# get index of predicted dog breed for each image in test set
VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]

# report test accuracy
test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)
print('Test accuracy: ',test_accuracy,'%')

"""#Prediction#"""

# Predict dog breed with the transfer learning model
def extract_VGG16(tensor):
	from keras.applications.vgg16 import VGG16, preprocess_input
	return VGG16(weights='imagenet', include_top=False).predict(preprocess_input(tensor))

def predict_VGG16(img_path):
  # extract bottleneck features
  bottleneck_feature = extract_VGG16(path_to_tensor(img_path))
  # obtain predicted vector
  predicted_vector = VGG16_model.predict(bottleneck_feature)
  # return dog breed that is predicted by the model
  breed = dog_names[np.argmax(predicted_vector)]
  return breed

def predict_scratch(img_path):
  # obtain predicted vector
  predicted_vector = model.predict(path_to_tensor(img_path))
  # return dog breed that is predicted by the model
  breed = dog_names[np.argmax(predicted_vector)]
  return breed

def predict_breed(img_path, model='VGG16'):
  if(model=='VGG16'):
    breed = predict_VGG16(img_path)

  if(model=='scratch'):
    breed = predict_scratch(img_path)
  
  # show image
  img = cv2.imread(img_path)
  cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  imgplot = plt.imshow(cv_rgb)

  # print prediction
  if face_detector(img_path) and not dog_detector(img_path): 
    print("Hi, human! You are a",breed,"in dog's world.")
  elif dog_detector(img_path) and not face_detector(img_path):
      print("Hi, dog! You are a",breed)
  else:
    print("Hi, unknown species! You are a",breed,"in dog's world.")

# Results
# Australian_shepherd
predict_breed('/content/dogImages/test/012.Australian_shepherd/Australian_shepherd_00868.jpg','scratch')
predict_breed('/content/dogImages/test/012.Australian_shepherd/Australian_shepherd_00868.jpg','VGG16')
